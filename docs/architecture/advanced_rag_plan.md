# OneBook AI — Advanced RAG 目标与执行基线

本文档用于固定 OneBook AI 的 RAG 演进目标。后续检索与问答相关改动，默认都应对齐本基线。

## 1. 当前判断（As-Is）
- 当前整体形态：`Modular RAG`（Gateway/Book/Ingest/Indexer/Chat 已模块化）。
- 当前检索能力：仍以 `Naive RAG` 为主（问题向量化 + TopK 向量检索 + 上下文拼接 + 生成）。

## 2. 目标状态（To-Be）
在不引入 Graph RAG / Agentic RAG 的前提下，先完成 `Advanced RAG`。

`Advanced RAG` 的定义：
- 检索前（Pre-retrieval）优化：提升召回覆盖与查询表达质量。
- 检索中（Retrieval）优化：提升相关性排序与上下文有效性。
- 检索后（Post-retrieval）优化：提升答案可追溯性、真实性与稳定性。

## 3. 重点改造范围
### 3.1 检索前（Pre-retrieval）
- 查询改写：口语问题规范化、术语归一、补充检索关键词。
- 多查询召回：复杂问题拆分为 2~N 个子查询并合并候选。
- 分块与元数据治理：持续优化 chunk 粒度与 overlap，保留可过滤元数据（章节/页码/来源等）。

### 3.2 检索中（Retrieval）
- 混合检索：向量检索 + 关键词检索（如 BM25）融合。
- 两阶段检索：先高召回 TopN，再重排（rerank）选出最终上下文。
- 去重与多样性：避免相邻重复 chunk 挤占上下文窗口。

### 3.3 检索后（Post-retrieval）
- 证据约束生成：回答必须基于检索证据并附引用。
- 证据不足兜底：上下文不足时明确说明“无法确定”，禁止臆测。
- 答案后校验：增加 groundedness/引用一致性检查，降低幻觉。

## 4. 里程碑顺序（默认）
1. P0：查询改写 + 多查询召回 + 去重（低风险、收益快）。
2. P1：混合检索（向量 + BM25）与重排链路。
3. P2：答案后校验与质量打分闭环。

## 5. 验收指标（每阶段都要看）
- 检索指标：Recall@K、nDCG@K、MRR。
- 生成指标：答案正确率、引用命中率、幻觉率。
- 工程指标：P95 延迟、单次问答成本、失败率。

## 6. 执行约束
- 默认小步迭代，不做一次性大改。
- 每次改动需明确：问题假设、方案、指标变化、回滚策略。
- 若引入新的 API 字段或错误语义，需同步更新 OpenAPI 与联调文档。

## 7. 已裁剪需求清单（按当前产品定位）
结合当前定位（个人/小团队、书本问答、MVP 先行），将 OCR/RAG 需求裁剪如下。

### 7.1 必做（纳入主路线）
- OCR：文档分型、输入质量门禁、页级策略、OCR 置信度利用、结果可追溯。
- 检索前：清洗规范、查询清洗一致性、结构化分块、重叠策略、元数据标准、增量重建。
- 索引：embedding 任务类型规范、向量维度/模型版本锁定、索引参数治理、混合检索、元数据过滤、召回去重。
- 检索中：查询改写、多查询召回、二阶段检索（召回 + 重排）、上下文打包、失败降级。
- 检索后：证据约束生成、不足证据拒答、引用一致性校验、结构化输出。
- 评测：评测集建设、检索指标、生成指标、切片评测、持续评测门禁。
- 工程治理：可观测性、特性开关、权限过滤、成本治理、回滚预案。

### 7.2 暂缓（后续按业务体量再引入）
- OCR 多语言自动路由（先以当前主语种与常见场景为准）。
- 表格/公式高保真恢复（当前 MVP 不要求复杂文档还原）。
- 重型合规体系（先做最小必要日志治理与敏感信息控制）。

### 7.3 当前阶段不做
- Graph RAG。
- Agentic RAG。
- 多人协作权限层级。
- 计费与精细化配额系统。

## 8. 可执行里程碑（M0-M5）
以下里程碑按“先质量基线，再检索增强，再评测闭环”的顺序推进。

### M0：基线固化（已开始）
- 目标：完成检索前清洗、chunk 元数据标准化、页级 OCR 融合基础能力。
- 交付：
  - 文档清洗与 chunk metadata 规范落地。
  - OCR 页级触发与 native/OCR 融合机制落地。
  - 可配置阈值与基础测试。
- 验收：
  - `backend/go test ./...` 全通过。
  - 可在 metadata 中追溯每个 chunk 的提取方式与来源位置。

### M1：检索前增强（Pre-retrieval）
- 目标：提升输入与查询质量，降低“召回不到”问题。
- 交付：
  - 查询改写与多查询召回管线（可开关）。
  - 分块策略升级（结构边界优先，保留章节层级）。
  - 增量重建与幂等重跑机制补齐。
- 验收：
  - 固定评测集上 Recall@K 相比 M0 可量化提升。
  - 关键路径延迟增幅可控（设定 P95 上限）。

### M2：检索中增强（Retrieval）
- 目标：从“能召回”提升到“召回更准、上下文更有效”。
- 交付：
  - 混合检索（向量 + 关键词）与融合打分。
  - 两阶段检索（TopN + rerank）。
  - 召回去重与上下文打包策略。
- 验收：
  - nDCG@K/MRR 提升。
  - 上下文冗余下降（重复 chunk 比例下降）。

### M3：检索后与生成约束（Post-retrieval）
- 目标：降低幻觉，提升可解释性与可追溯性。
- 交付：
  - 证据约束生成模板。
  - 证据不足拒答策略。
  - 答案-引用一致性校验（groundedness 检查）。
- 验收：
  - 引用命中率提升。
  - 幻觉率下降，且拒答正确率可量化。

### M4：评测与发布门禁
- 目标：形成“可持续迭代”的质量闭环。
- 交付：
  - 评测集（离线 + 线上抽样）。
  - 指标看板（Recall@K、MRR、nDCG、正确率、幻觉率、P95、成本）。
  - CI/发布门禁阈值（低于阈值阻断发布）。
- 验收：
  - 每次关键改动均有可复现实验结果与回归报告。

### M5：运维治理与灰度
- 目标：降低线上变更风险，提升可运营性。
- 交付：
  - 特性开关（OCR、混合检索、重排、拒答策略）。
  - 灰度发布与快速回滚预案。
  - 成本预算与异常告警。
- 验收：
  - 支持按流量/租户灰度开启新策略。
  - 故障可在预设时间窗内回滚到稳定版本。
